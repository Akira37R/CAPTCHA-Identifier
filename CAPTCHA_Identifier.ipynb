{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1> CAPTCHA Recognition Based on Convolutional Neural Network </h1></center>\n",
        "\n",
        "**Author**: Akira37\n",
        "\n",
        "**Correspondence**: Email: hyperplasma@qq.com\n",
        "\n",
        "**Abstract**: When a crawler encounters an image CAPTCHA system, a CAPTCHA recognition program is needed. This project uses PyTorch to build a deep learning model based on a Convolutional Neural Network (CNN) to recognize complex CAPTCHA images composed of numbers and letters. Here we use the captcha library's built-in generator to produce tens of thousands of images and divide them into train sets and test sets. Through PyTorch framework, a CNN model is built and later trained for a certain number of rounds, and finally the result model achieve a relatively accurate recognition rate.\n",
        "\n",
        "**Keywords**: CAPTCHA Recognition; Convolutional Neural Network; Deep Learning; PyTorch\n",
        "\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1d5ee1eb14841596"
      },
      "id": "1d5ee1eb14841596"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Pre-procession"
      ],
      "metadata": {
        "collapsed": false,
        "id": "81f2c27ac09b6530"
      },
      "id": "81f2c27ac09b6530"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5aa03fb7e6c68cde"
      },
      "id": "5aa03fb7e6c68cde"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting captcha\n",
            "  Downloading captcha-0.5.0-py3-none-any.whl (102 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/102.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from captcha) (9.4.0)\n",
            "Installing collected packages: captcha\n",
            "Successfully installed captcha-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install captcha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_id",
        "outputId": "8c8e7bc0-5524-49a8-dae0-af88f60bcfc7"
      },
      "id": "initial_id"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Versions of Required Packages---\n",
            "torch: 2.2.1+cu121\n",
            "torchvision: 0.17.1+cu121\n",
            "pillow: 9.4.0\n",
            "captcha: 0.5.0\n",
            "matplotlib: 3.7.1\n"
          ]
        }
      ],
      "source": [
        "import concurrent.futures\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "import PIL\n",
        "import captcha\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from captcha.image import ImageCaptcha\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "print(\"---Versions of Required Packages---\")\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"torchvision:\", torchvision.__version__)\n",
        "print(\"pillow:\", PIL.__version__)\n",
        "print(\"captcha:\", captcha.__version__)\n",
        "print(\"matplotlib:\", matplotlib.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27b162750aa9e472",
        "outputId": "f4c3e4e2-70a8-490a-daf8-6250e9bc344b"
      },
      "id": "27b162750aa9e472"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Hyper-parameters"
      ],
      "metadata": {
        "collapsed": false,
        "id": "4c36263df79d9a95"
      },
      "id": "4c36263df79d9a95"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "CHAR_NUMBER = 4                                 # Number of characters in the image CAPTCHA\n",
        "IMG_WIDTH = 160                                 # Image width\n",
        "IMG_HEIGHT = 60                                 # Image height\n",
        "SEED = \"0123456789abcdefghijkmnpqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ\"   # Character pool\n",
        "\n",
        "TRAIN_SIZE = 30000      # Size of train set\n",
        "VALIDATION_SIZE = 10000   # Size of validation set\n",
        "TEST_SIZE = 10000       # Size of test set\n",
        "\n",
        "BATCH_SIZE = 60             # Number of images in a mini-batch\n",
        "TOTAL_EPOCH = 30             # Training rounds\n",
        "LEARNING_RATE = 1e-3        # Learning rate for backpropagation"
      ],
      "metadata": {
        "id": "7302c747f9431b99"
      },
      "id": "7302c747f9431b99"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"     # Run this model on GPU if possible\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4124f32773ea5ae7",
        "outputId": "5fd638ab-36f3-415b-f500-1b93010f29ee"
      },
      "id": "4124f32773ea5ae7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Path format: \"./{folder}\" (run locally) or \"/content/{folder}\" (run on Google Colab)\n",
        "\n",
        "# train_set_path = \"./data/train\"\n",
        "# validation_set_path = './data/validation'\n",
        "# test_set_path = \"./data/test\"\n",
        "# save_file_path = \"./result/model.pth\"\n",
        "\n",
        "train_set_path = \"/content/data/train\"\n",
        "validation_set_path = '/content/data/validation'\n",
        "test_set_path = \"/content/data/test\"\n",
        "save_file_path = \"/content/result/model.pth\""
      ],
      "metadata": {
        "id": "6dd947b360ea2c8e"
      },
      "id": "6dd947b360ea2c8e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Visualization\n",
        "epoch_list = []\n",
        "train_loss_list = []\n",
        "valid_loss_list = []"
      ],
      "metadata": {
        "id": "47491443369f9985"
      },
      "id": "47491443369f9985"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Generate Data"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5b47642d0aeeee8"
      },
      "id": "5b47642d0aeeee8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def captcha_generator(num, output_dir, thread_name=0):\n",
        "    if Path(output_dir).exists():\n",
        "        shutil.rmtree(output_dir)   # If the directory already exists, delete it before creating a new one.\n",
        "    Path(output_dir).mkdir()\n",
        "\n",
        "    for i in range(num):\n",
        "        image_captcha = ImageCaptcha(width=IMG_WIDTH, height=IMG_HEIGHT)\n",
        "\n",
        "        chars = \"\".join([random.choice(SEED) for _ in range(CHAR_NUMBER)])  # Randomly choose an element in the char-pool for the CAPTCHA string.\n",
        "        save_path = f\"{output_dir}/{i + 1}-{chars}.png\"     # The default output format is png.\n",
        "\n",
        "        image_captcha.write(chars, save_path)\n",
        "        # if (i + 1) % (num / 10) == 0:\n",
        "        #     print(f\"Thread {thread_name}: {i + 1} CAPTCHA code{'s' if i > 0 else ''} ha{'ve' if i > 0 else 's'} been generated. \")\n",
        "\n",
        "    print(f\"Thread {thread_name}: Congrats! All {num} CAPTCHA code{'s' if num > 0 else ''} ha{'ve' if num > 0 else 's'} been generated at {output_dir} \")"
      ],
      "metadata": {
        "id": "4e6fa01af0d3abe1"
      },
      "id": "4e6fa01af0d3abe1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thread 2: Congrats! All 10000 CAPTCHA codes have been generated at /content/data/validation \n",
            "Thread 1: Congrats! All 10000 CAPTCHA codes have been generated at /content/data/test \n"
          ]
        }
      ],
      "source": [
        "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:     # Multithread generation.\n",
        "    # executor.submit(captcha_generator, 3, \"./data\", 1)\n",
        "    executor.submit(captcha_generator, TRAIN_SIZE, train_set_path, 0)\n",
        "    executor.submit(captcha_generator, TEST_SIZE, test_set_path, 1)\n",
        "    executor.submit(captcha_generator, VALIDATION_SIZE, validation_set_path, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c05a2b05af83cec7",
        "outputId": "250eb60d-93a7-4e5f-88a3-89d125fcff2e"
      },
      "id": "c05a2b05af83cec7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "for filename in os.listdir(train_set_path):\n",
        "    image = Image.open(train_set_path + \"/\" + filename)\n",
        "    image.show()\n",
        "    print(image)\n",
        "    break"
      ],
      "metadata": {
        "id": "a4615f8985b394e1"
      },
      "id": "a4615f8985b394e1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Load Data"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1e7e75416eede4d1"
      },
      "id": "1e7e75416eede4d1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-hot Code"
      ],
      "metadata": {
        "collapsed": false,
        "id": "b2c3e2ffe47b7957"
      },
      "id": "b2c3e2ffe47b7957"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def one_hot_encode(chars):\n",
        "    \"\"\"Convert Characters to One-hot Codes\"\"\"\n",
        "    cols = len(SEED)\n",
        "    rows = CHAR_NUMBER\n",
        "    res = torch.zeros(rows, cols, dtype=torch.float32)  # Initialize the result tensor (can combine first two arguments to be a tuple for some reason)\n",
        "\n",
        "    for i, char in enumerate(chars):\n",
        "        j = SEED.index(char)    # The column index (j) is the position of a character in the char-pool string\n",
        "        res[i, j] = 1.0         # Set the j-th element in the i-th row to be 1\n",
        "\n",
        "    return res.view(1, -1)[0]   # Reshape and return the tensor as a row vector."
      ],
      "metadata": {
        "id": "f9bc8d2dbbf633f6"
      },
      "id": "f9bc8d2dbbf633f6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def one_hot_decode(code):\n",
        "    \"\"\"Revert One-hot Codes to Characters\"\"\"\n",
        "    code = code.view(-1, len(SEED)) # Reshape the row vector (one-hot code)\n",
        "    index_list = torch.argmax(code, dim=1)  # Return a tensor containing the indices of the respective biggest values in every line (column/dim-1 indices), i.e. every index is determined by its character that has the biggest possibilities!\n",
        "    chars = \"\".join([SEED[i] for i in index_list])  # Restore the characters respectively.\n",
        "    return chars"
      ],
      "metadata": {
        "id": "70310827c4c89d1f"
      },
      "id": "70310827c4c89d1f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "temp_code = one_hot_encode(\"TEST\")\n",
        "print(temp_code)\n",
        "print(temp_code.shape)\n",
        "print(one_hot_decode(temp_code))"
      ],
      "metadata": {
        "id": "f9629ab8c36b7193"
      },
      "id": "f9629ab8c36b7193"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Data Loader"
      ],
      "metadata": {
        "collapsed": false,
        "id": "27108fc6bce37812"
      },
      "id": "27108fc6bce37812"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, dir_path):\n",
        "        super(ImageDataset, self).__init__()\n",
        "        self.img_path_list = [f\"{dir_path}/{filename}\" for filename in os.listdir(dir_path)]    # Load all the paths of images in the data set.\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Grayscale(),\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.transform(Image.open(self.img_path_list[index]))\n",
        "        label = self.img_path_list[index].split(\"-\")[-1].replace(\".png\", \"\")    # Detach the characters from leading numbers and the file format(\".png\")\n",
        "        label = one_hot_encode(label)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path_list)"
      ],
      "metadata": {
        "id": "d31b6361c460bacb"
      },
      "id": "d31b6361c460bacb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def get_dataloader(path):\n",
        "    dataset = ImageDataset(path)\n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)   # Actually not necessary to re-shuffle the already shuffled data generated.\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "a1cf5e1219f84a3a"
      },
      "id": "a1cf5e1219f84a3a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# View the shape of tensors.\n",
        "train_dataloader = get_dataloader(train_set_path)\n",
        "test_dataloader = get_dataloader(test_set_path)\n",
        "for inputs, targets in train_dataloader:\n",
        "    # print(inputs)\n",
        "    print(inputs.shape)\n",
        "    # print(targets)\n",
        "    print(targets.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "a8e6e1895c7fa3d9"
      },
      "id": "a8e6e1895c7fa3d9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Design Model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5cdfd334b973e8e9"
      },
      "id": "5cdfd334b973e8e9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class NeuralNetWork(nn.Module):\n",
        "    \"\"\"Convolutional Neural Network (VGG-16)\n",
        "\n",
        "    Layout:\n",
        "        1. Conv_1x64 -> ReLU -> MaxPool_2x2\n",
        "        2. Conv_64x128 -> ReLU -> MaxPool_2x2\n",
        "        3. Conv_128x256 -> ReLU -> MaxPool_2x2\n",
        "        4. Conv_256x512 -> ReLU -> MaxPool_2x2\n",
        "        5. FC -(drop out)-> ReLU -> FC\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(NeuralNetWork, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=15360, out_features=4096),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4096, out_features=CHAR_NUMBER * len(SEED))   # The number of predictions must be the CAPTCHA character number times the length of the character pool\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ab7540261dda9e10"
      },
      "id": "ab7540261dda9e10"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Train Model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "86b4617db46cc9d2"
      },
      "id": "86b4617db46cc9d2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Cycles"
      ],
      "metadata": {
        "collapsed": false,
        "id": "13f6bdc5722eb295"
      },
      "id": "13f6bdc5722eb295"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_func, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for batch, (inputs, targets) in enumerate(dataloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_func(outputs, targets)  # Forward propagation\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()                     # Backpropagation\n",
        "        optimizer.step()                    # Optimization\n",
        "\n",
        "        # if (batch + 1) % (BATCH_SIZE / 10) == 0:\n",
        "        #     print(f\"Batch {batch + 1}: Loss = {loss:>7f}\")\n",
        "\n",
        "    # print(f\"Total loss on Train Set is {running_loss:>7f}\")\n",
        "    return running_loss"
      ],
      "metadata": {
        "id": "a8743eba5c1272a"
      },
      "id": "a8743eba5c1272a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def validate(dataloader, model, loss_func):\n",
        "    model.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():   # No backpropagation during evaluating the model\n",
        "        for batch, (inputs, targets) in enumerate(dataloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_func(outputs, targets)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "    # print(f\"Total loss on Validation Set is {running_loss:>7f}\")\n",
        "    return running_loss"
      ],
      "metadata": {
        "id": "67dfb494b3e15ed2"
      },
      "id": "67dfb494b3e15ed2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model = NeuralNetWork().to(device)\n",
        "loss_func = nn.MultiLabelSoftMarginLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "92ae58dc82befb6e"
      },
      "id": "92ae58dc82befb6e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function: MultiLabelSoftMarginLoss (Multi-Label Cross-Entropy)\n",
        "$$\n",
        "loss(x,y)=-\\frac{1}{C}\\sum\\limits_{i}(y^{(i)}\\log(1+\\exp(-x^{(i)}))^{-1}+(1-y^{(i)})\\log\\frac{\\exp(-x^{(i)})}{1+\\exp(-x^{(i)})})\n",
        "$$\n",
        "where $x$ is the input tensor whose shape is $(N,C)$ (batch size and number of classification), and $y$ is the real label with the same shape."
      ],
      "metadata": {
        "collapsed": false,
        "id": "HcB9BhL1Pylz"
      },
      "id": "HcB9BhL1Pylz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "train_dataloader = get_dataloader(train_set_path)\n",
        "validation_dataloader = get_dataloader(validation_set_path)\n",
        "\n",
        "for epoch in range(TOTAL_EPOCH):\n",
        "    # print(f\"--------------- Training Epoch {epoch + 1} ---------------\")\n",
        "    epoch_list.append(epoch + 1)\n",
        "\n",
        "    train_loss = train(train_dataloader, model, loss_func, optimizer)\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    valid_loss = validate(validation_dataloader, model, loss_func)\n",
        "    valid_loss_list.append(valid_loss)\n",
        "    print()\n",
        "\n",
        "torch.save(model.state_dict(), save_file_path)\n",
        "print(f\"The {TOTAL_EPOCH}-epoch training is complete and the model is saved at \\\"{save_file_path}\\\"\")"
      ],
      "metadata": {
        "id": "23b3cb2954bf5a31"
      },
      "id": "23b3cb2954bf5a31"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "collapsed": false,
        "id": "3de4876a0bde2de1"
      },
      "id": "3de4876a0bde2de1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.plot(epoch_list, train_loss_list)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss on Training Set')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c048ed544ff28052"
      },
      "id": "c048ed544ff28052"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.plot(epoch_list, valid_loss_list)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss on Validation Set')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4aa779a93e578fd7"
      },
      "id": "4aa779a93e578fd7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Test Model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "4f328fe019417377"
      },
      "id": "4f328fe019417377"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def predict(model, file_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Grayscale(),\n",
        "    ])\n",
        "\n",
        "    with torch.no_grad():   # No backpropagation during using the model\n",
        "        inputs = transform(Image.open(file_path)).reshape(1, 1, 60, 160).to(device)     # All tensors(operators) should be on the same device.\n",
        "        outputs = model(inputs)\n",
        "        # print(outputs)\n",
        "        chars = one_hot_decode(outputs)\n",
        "        return chars\n",
        "\n",
        "\n",
        "def recognize(model, file_path):\n",
        "    model.eval()\n",
        "    real_captcha = file_path.split(\"-\")[-1].replace(\".png\", \"\")     # File name formation: {index}-{characters}.{file format}\n",
        "    pred_captcha = predict(model, file_path)\n",
        "\n",
        "    correct = 1 if pred_captcha == real_captcha else 0\n",
        "    # if pred_captcha == real_captcha:\n",
        "    #     print(f\"The prediction result of \\\"{file_path}\\\" is {pred_captcha}. The prediction is CORRECT!\")\n",
        "    # else:\n",
        "    #     print(f\"The prediction result of \\\"{file_path}\\\" is {pred_captcha}. The prediction is WRONG!\")\n",
        "    return correct"
      ],
      "metadata": {
        "id": "de5f519a40c57210"
      },
      "id": "de5f519a40c57210"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def model_test(model):\n",
        "    correct = 0\n",
        "    total = len(os.listdir(test_set_path))\n",
        "    for filename in os.listdir(test_set_path):\n",
        "        file_path = f\"{test_set_path}/{filename}\"\n",
        "        correct += recognize(model, file_path)\n",
        "    accuracy = f\"{correct / total * 100:.7f}%\"\n",
        "    print(\"\\nThe accuracy of the model is\", accuracy)"
      ],
      "metadata": {
        "id": "68160ec8197f31cd"
      },
      "id": "68160ec8197f31cd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model = NeuralNetWork().to(device)\n",
        "model.load_state_dict(torch.load(save_file_path, map_location=torch.device(device)))\n",
        "\n",
        "model_test(model)"
      ],
      "metadata": {
        "id": "87552782c5d9f152"
      },
      "id": "87552782c5d9f152"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}