{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<center><h1> CAPTCHA Identifier </h1></center>\n",
    "\n",
    "Author: Akira37\n",
    "\n",
    "Abstract: When a crawler encounters a CAPTCHA system, a CAPTCHA recognition program is needed. This project uses PyTorch to build a Convolutional Neural Network (CNN) to recognize complex image CAPTCHA composed of numbers and letters. Here we use the captcha library's built-in generator to generate tens of thousands of graphs and divide them into train sets and test sets. Through PyTorch framework, a CNN model is built and later trained for a certain number of rounds, and finally the result model achieve a relatively accurate recognition rate.\n",
    "\n",
    "Keywords: Image CAPTCHA; Convolutional Neural Network; Deep Learning; PyTorch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d5ee1eb14841596"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is an image CAPTCHA identifier based on a Convolutional Neural Network model. My FIRST-EVER PyTorch project!\n",
    "\n",
    "CAPTCHA: Completely Automated Public Turing test to tell Computers and Humans Apart (or simply Verification Code)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "462604173575e431"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-procession"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81f2c27ac09b6530"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Packages"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5aa03fb7e6c68cde"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install captcha"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import PIL\n",
    "import captcha\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from captcha.image import ImageCaptcha\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "print(\"---Versions of Required Packages---\")\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"pillow:\", PIL.__version__)\n",
    "print(\"captcha:\", captcha.__version__)\n",
    "print(\"matplotlib:\", matplotlib.__version__)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27b162750aa9e472"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyper-parameter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c36263df79d9a95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CHAR_NUMBER = 4                                 # Number of characters in the image CAPTCHA\n",
    "IMG_WIDTH = 160                                 # Image width\n",
    "IMG_HEIGHT = 60                                 # Image height\n",
    "SEED = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"   # Character pool\n",
    "\n",
    "TRAIN_SIZE = 300      # Size of train set\n",
    "VALIDATION_SIZE = 100   # Size of validation set\n",
    "TEST_SIZE = 100       # Size of test set\n",
    "\n",
    "BATCH_SIZE = 60             # Number of images in a mini-batch\n",
    "TOTAL_EPOCH = 25             # Training rounds\n",
    "LEARNING_RATE = 1e-3        # Learning rate while backward\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# On Google Colab, change paths to \"/content/\" + ???\n",
    "train_set_path = \"./data/train\"\n",
    "validation_set_path = './data/validation'\n",
    "test_set_path = \"./data/test\"\n",
    "save_file_path = \"./result/model.pth\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7302c747f9431b99"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epoch_list = []\n",
    "train_acc_list = []\n",
    "valid_acc_list = []"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47491443369f9985"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b47642d0aeeee8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Image CAPTCHA Generator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe06b7c5874f90b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def captcha_generator(num, output_dir, thread_name=0):\n",
    "    if Path(output_dir).exists():\n",
    "        shutil.rmtree(output_dir)   # If the directory already exists, delete it before creating the new one.\n",
    "    Path(output_dir).mkdir()\n",
    "\n",
    "    for i in range(num):\n",
    "        image_captcha = ImageCaptcha(width=IMG_WIDTH, height=IMG_HEIGHT)\n",
    "\n",
    "        chars = \"\".join([random.choice(SEED) for _ in range(CHAR_NUMBER)])  # Generate characters randomly\n",
    "        save_path = f\"{output_dir}/{i + 1}-{chars}.png\"\n",
    "\n",
    "        image_captcha.write(chars, save_path)\n",
    "        print(f\"Thread {thread_name}: {i + 1} CAPTCHA code{'s' if i > 0 else ''} ha{'ve' if i > 0 else 's'} been \"\n",
    "              f\"generated. \")\n",
    "\n",
    "    print(f\"Thread {thread_name}: Congrats! All CAPTCHA codes have been generated! \")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e6fa01af0d3abe1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multithread Generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c8fa3ab9e0253fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor: \n",
    "    # executor.submit(captcha_generator, 3, \"data\", 1)\n",
    "    executor.submit(captcha_generator, TRAIN_SIZE, train_set_path, 0)\n",
    "    executor.submit(captcha_generator, TEST_SIZE, test_set_path, 1)\n",
    "    executor.submit(captcha_generator, VALIDATION_SIZE, validation_set_path, 2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c05a2b05af83cec7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Progress and Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e7e75416eede4d1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One-hot Coding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2c3e2ffe47b7957"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def one_hot_encode(chars):\n",
    "    \"\"\"Convert Characters to One-hot Codes\"\"\"\n",
    "    cols = len(SEED)\n",
    "    rows = CHAR_NUMBER\n",
    "    res = torch.zeros(rows, cols, dtype=torch.float32)\n",
    "\n",
    "    for i, char in enumerate(chars):\n",
    "        j = SEED.index(char)\n",
    "        res[i, j] = 1.0\n",
    "\n",
    "    return res.view(1, -1)[0]\n",
    "\n",
    "def one_hot_decode(code):\n",
    "    \"\"\"Revert One-hot Codes to Characters\"\"\"\n",
    "    code = code.view(-1, len(SEED))\n",
    "    index_list = torch.argmax(code, dim=1)\n",
    "    chars = \"\".join([SEED[i] for i in index_list])\n",
    "    return chars"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T12:58:53.978100Z",
     "start_time": "2024-03-27T12:58:53.966291Z"
    }
   },
   "id": "f9bc8d2dbbf633f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Data Loader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27108fc6bce37812"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dir_path):\n",
    "        super(ImageDataset, self).__init__()\n",
    "        self.img_path_list = [f\"{dir_path}/{filename}\" for filename in os.listdir(dir_path)]\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Grayscale(),\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.transform(Image.open(self.img_path_list[index]))\n",
    "        label = self.img_path_list[index].split(\"-\")[-1].replace(\".png\", \"\")\n",
    "        label = one_hot_encode(label)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d31b6361c460bacb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_dataloader(path):\n",
    "    dataset = ImageDataset(path)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    return dataloader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1cf5e1219f84a3a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# View the shape of tensors.\n",
    "train_dataloader = get_dataloader(train_set_path)\n",
    "test_dataloader = get_dataloader(test_set_path)\n",
    "for inputs, targets in train_dataloader:\n",
    "    print(inputs.shape)\n",
    "    print(targets.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8e6e1895c7fa3d9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Design Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cdfd334b973e8e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class NeuralNetWork(nn.Module):\n",
    "    \"\"\"Convolutional Neural Network\"\"\"\n",
    "    def __init__(self):\n",
    "        super(NeuralNetWork, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=15360, out_features=4096),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=4096, out_features=CHAR_NUMBER * len(SEED))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab7540261dda9e10"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86b4617db46cc9d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_func, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, targets)\n",
    "        \n",
    "        total += targets.size(0)\n",
    "        correct += (outputs == targets).sum().item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % (BATCH_SIZE / 10) == 0:\n",
    "            print(f\"Batch {batch + 1}: Loss = {loss:>8f}\")\n",
    "    \n",
    "    accuracy = 1.0 * correct / total\n",
    "    print(f\"Accuracy on Train Set is {accuracy:>7f}\")\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8743eba5c1272a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validate(dataloader, model, loss_func):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (inputs, targets) in enumerate(dataloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            total += targets.size(0)\n",
    "            correct += (outputs == targets).sum().item()\n",
    "    \n",
    "    accuracy = 1.0 * correct / total\n",
    "    print(f\"Accuracy on Validation Set is {accuracy:>8f}\")\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67dfb494b3e15ed2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = NeuralNetWork().to(device)\n",
    "loss_func = nn.MultiLabelSoftMarginLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_dataloader = get_dataloader(train_set_path)\n",
    "validation_dataloader = get_dataloader(validation_set_path)\n",
    "\n",
    "for epoch in range(TOTAL_EPOCH):\n",
    "    print(f\"--------------- Training Epoch {epoch + 1} ---------------\")\n",
    "    epoch_list.append(epoch + 1)\n",
    "    \n",
    "    train_acc = train(train_dataloader, model, loss_func, optimizer)\n",
    "    train_acc_list.append(train_acc)\n",
    "    \n",
    "    valid_acc = validate(validation_dataloader, model, loss_func)\n",
    "    valid_acc_list.append(valid_acc)\n",
    "    print()\n",
    "\n",
    "torch.save(model.state_dict(), save_file_path)\n",
    "print(f\"The training is complete and the model is saved at \\\"{save_file_path}\\\"\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23b3cb2954bf5a31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3de4876a0bde2de1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epoch_list, train_acc_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy on Training Set')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c048ed544ff28052"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epoch_list, valid_acc_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy on Validation Set')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4aa779a93e578fd7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f328fe019417377"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict(model, file_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Grayscale(),\n",
    "    ])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = transform(Image.open(file_path)).reshape(1, 1, 60, 160).to(device) # All tensors(operators) should be on the same device!\n",
    "        outputs = model(inputs)\n",
    "        # print(outputs)\n",
    "        chars = one_hot_decode(outputs)\n",
    "        return chars"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de5f519a40c57210"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = NeuralNetWork().to(device)\n",
    "model.load_state_dict(torch.load(save_file_path, map_location=torch.device(\"cpu\")))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "test_dir = test_set_path\n",
    "total = len(os.listdir(test_dir))\n",
    "for filename in os.listdir(test_dir):\n",
    "    file_path = f\"{test_dir}/{filename}\"\n",
    "    real_captcha = file_path.split(\"-\")[-1].replace(\".png\", \"\")\n",
    "    pred_captcha = predict(model, file_path)\n",
    "\n",
    "    if pred_captcha == real_captcha:\n",
    "        correct += 1\n",
    "        print(f\"The prediction result of \\\"{file_path}\\\" is {pred_captcha}. The prediction is CORRECT!\")\n",
    "    else:\n",
    "        print(f\"The prediction result of \\\"{file_path}\\\" is {pred_captcha}. The prediction is WRONG!\")\n",
    "\n",
    "accuracy = f\"{correct / total * 100:.8f}%\"\n",
    "print(\"\\nThe accuracy of the model is\", accuracy)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68160ec8197f31cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
